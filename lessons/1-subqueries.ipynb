{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "881b56b7-4005-480d-83c5-4a5eddb6d6ed",
   "metadata": {},
   "source": [
    "# Modifying the Query Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93328380-edfb-44e2-afc8-d255a837bfbc",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67ff76d-cfc0-41a4-a798-c2485435bab1",
   "metadata": {},
   "source": [
    "Now so far in querying our database, we have used an approach of taking the question, and then using that original question to find a suitable answer.\n",
    "\n",
    "As we'll see in this lesson, we can also set up our pipeline to modify the user's question to help with retrieving the correct documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e299d459-242a-4945-84f8-696564e7d8f6",
   "metadata": {},
   "source": [
    "### Seeing the Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed5b9ab-cf58-4517-8566-980c9abde39f",
   "metadata": {},
   "source": [
    "We can begin to see the how breaking a question into different components can help us if we have a fairly complicated question.  For example, say we have a question like:\n",
    "\n",
    "\"Please explain the causes of WWI.  In your explanation, include information on the Balkans, overlapping alliances, and the growth of Germany.\"\n",
    "\n",
    "Now if we just embedded this entire question and looked for a match, we would be likely to only retrieve documents that mention all three.  So we can get a more in depth answer if our query engine first breaks this question into parts, then finds the best matches for each of these parts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a562340c-1526-46dc-8854-845617b4cdc4",
   "metadata": {},
   "source": [
    "### Trying it out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125d0759-9aa8-4f0f-8d87-dad5cc5960cf",
   "metadata": {},
   "source": [
    "Run `python3 -i index.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc74407-e22b-4075-900f-df7b379fac6b",
   "metadata": {},
   "source": [
    "<img src=\"./seeing-subquestions.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e08860-abf5-4e30-a10a-f933c50aa405",
   "metadata": {},
   "source": [
    "You can see how this works.  The first step is to break our larger question into three separate questions, and answer then separately.  And in answering each separate question, it runs a different query to look for the related documents/nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead9cbaa-faad-40f5-aa6f-42ad26afcc28",
   "metadata": {},
   "source": [
    "<img src=\"./query-retrieve.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b896e9-ec34-4cf7-9c9a-1ecd11e7f42e",
   "metadata": {},
   "source": [
    "So the strategy here is essentially to recognize that different nodes may have expertise on different components of our question.  So asking three different questions, and then performing three separate queries - we can find the experts on each component to answer our question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad8fb60-98ce-43cb-a596-8d10fc8eda7c",
   "metadata": {},
   "source": [
    "* Asking a generic question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b62b16-bac3-4ad0-9f3c-9feaffe9afdf",
   "metadata": {},
   "source": [
    "Notice that if we ask a less wordy question, our query engine will still do it's best to break this question into subcomponents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655b8ace-e0c2-45d1-9138-93d37baa525e",
   "metadata": {},
   "source": [
    "<img src=\"./queries-generic.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5746d205-29eb-4b1f-9bdc-92696130e711",
   "metadata": {},
   "source": [
    "### Implementing subqueries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a18e9e-fce0-4dcd-a44a-af5ebd4c2cb4",
   "metadata": {},
   "source": [
    "To implement our subqueries, we first set up some tracing, so we can see some of the subqueries.  This we performed through our debug handler and the callback manager."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad1341d-c1cf-40b3-a73a-ff058aea0bfe",
   "metadata": {},
   "source": [
    "```python\n",
    "llama_debug = LlamaDebugHandler(print_trace_on_end=True)\n",
    "callback_manager = CallbackManager([llama_debug])\n",
    "Settings.callback_manager = callback_manager\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3ba5ae-a93d-4f0d-a9d9-9f58108de5c4",
   "metadata": {},
   "source": [
    "From there after creating our query engine line normal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfb8da3-6fd4-4327-aef8-20df5f9a81a1",
   "metadata": {},
   "source": [
    "```python\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a30bb9-9946-43f3-a077-04c52d11462d",
   "metadata": {},
   "source": [
    "We then set up a QueryEngineTool, passing through the original query engine.   And finally, pass this `queryenginetools` into the `SubQuestionQueryEngine`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af127f23-8816-49f7-8e42-51fc9fb91064",
   "metadata": {},
   "source": [
    "```python\n",
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=query_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"ww1\",\n",
    "            description=\"WWI causes\",\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "query_engine = SubQuestionQueryEngine.from_defaults(\n",
    "    query_engine_tools=query_engine_tools)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bdb028-5cb1-4dd0-9346-d83a1bd10246",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f9f948-6553-4072-8f99-01d289e920c0",
   "metadata": {},
   "source": [
    "In this lesson we learned about using pre-processing our queries with subquestion queries.  The logic is that we may want to find documents specific about each component of a question, and not the question as a whole.  In this way, we can find information particular to each component of that question.  \n",
    "\n",
    "So with the SubQuestion query, multiple questions are generated from the initial question.  From there, a separate query is generated for each subquestion, and then the results are synthesized in a response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d298090-d37f-420d-9334-cffa35245d02",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "[Nanonets- Llamaindex](https://nanonets.com/blog/llamaindex/#using-index-to-query-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd09031-806a-46a2-aa3b-7061717ec600",
   "metadata": {},
   "source": [
    "[Toolify AI](https://www.toolify.ai/ai-news/unleash-the-power-of-sub-question-query-engine-for-complex-queries-1195226)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26458c6-cf16-4699-bc89-7c30c25f109a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
